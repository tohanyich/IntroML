{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальное задание по анализу данных из Dota2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.cross_validation as cross_val\n",
    "import time, datetime\n",
    "\n",
    "X = features = pd.read_csv('./features.csv', index_col='match_id')\n",
    "y = target = features[u'radiant_win']\n",
    "\n",
    "del features[u'duration'],features[u'radiant_win'], features[u'tower_status_radiant']\n",
    "del features[u'tower_status_dire'],features[u'barracks_status_radiant'], features[u'barracks_status_dire']\n",
    "\n",
    "str_num,col_num = features.shape\n",
    "col_names = features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 1: градиентный бустинг \"в лоб\"\n",
    "Выведем столбцы с пропусками и сразу же заполним пропущенные элементы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19553 Null elements in column first_blood_time\n",
      "19553 Null elements in column first_blood_team\n",
      "19553 Null elements in column first_blood_player1\n",
      "43987 Null elements in column first_blood_player2\n",
      "15691 Null elements in column radiant_bottle_time\n",
      "692 Null elements in column radiant_courier_time\n",
      "27479 Null elements in column radiant_flying_courier_time\n",
      "1836 Null elements in column radiant_first_ward_time\n",
      "16143 Null elements in column dire_bottle_time\n",
      "676 Null elements in column dire_courier_time\n",
      "26098 Null elements in column dire_flying_courier_time\n",
      "1826 Null elements in column dire_first_ward_time\n"
     ]
    }
   ],
   "source": [
    "for name in col_names:\n",
    "    num = features[name].count()\n",
    "    if num < str_num:\n",
    "        features[name] = features[name].fillna(value = 0)\n",
    "        print('%d Null elements in column %s') %(str_num - num, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "Пропущенные значения в столбцах признаков события first_blood_time, first_blood_team, first_blood_player1 скорее всего связаны с тем, что за первые 5 минут события не произошло. В столбце first_blood_player2 нулевых значений гораздо больше, наверно оно используется, если событие происходит одновременно, а это бывает редко. \n",
    "Аналогично столбцы признаков команд.\n",
    "#### Как называется столбец, содержащий целевую переменную?\n",
    "Целевой столбец radiant_win. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:01:49.062409\n",
      "trees number = 10, score = 0.664641\n",
      "Time elapsed: 0:03:38.642305\n",
      "trees number = 20, score = 0.681212\n",
      "Time elapsed: 0:05:05.655119\n",
      "trees number = 30, score = 0.688616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import grid_search\n",
    "\n",
    "cv = cross_val.KFold(len(features),n_folds=5, shuffle=True)\n",
    "for n_estimator in [10,20,30]:\n",
    "    GBC = GradientBoostingClassifier(n_estimators=n_estimator)\n",
    "    start_time = datetime.datetime.now()\n",
    "    score = cross_val.cross_val_score(GBC, features, target, cv = cv, scoring='roc_auc').mean()\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "    print ('trees number = %d, score = %f') % (n_estimator, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти ниже по тексту. Какое качество при этом получилось? \n",
    "Обучение по 30 деревьям шло 3 минуты 48 секунд, при этом качество оказалось 69%, что на 1% процент больше, чем при использовании 20 деревьев, а время время обучение увеличилось примерно на 50%.\n",
    "#### Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?\n",
    "В данном случае увеличение времени обучения не критичное, поэтому возможно имеет смысл использовать 30 деревьев. \n",
    "Для ускорения обучения можно, например, сократить количество признаков при помощи метода главных компонент.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 2: логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:23.111543\n",
      "regularization strength = 0.005000, score = 0.653996\n",
      "Time elapsed: 0:00:23.544226\n",
      "regularization strength = 0.006000, score = 0.653948\n",
      "Time elapsed: 0:00:20.906021\n",
      "regularization strength = 0.007000, score = 0.653925\n",
      "Time elapsed: 0:00:24.493259\n",
      "regularization strength = 0.008000, score = 0.653905\n",
      "Time elapsed: 0:00:27.264751\n",
      "regularization strength = 0.009000, score = 0.653884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X = StandardScaler().fit_transform(features)\n",
    "\n",
    "for reg in np.arange(0.005,0.01,0.001):\n",
    "    LR = LogisticRegression(penalty = 'l2', C = reg)\n",
    "    start_time = datetime.datetime.now()\n",
    "    predict = cross_val.cross_val_predict(LR, X, target, cv = cv)\n",
    "    score = roc_auc_score(target,predict)\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "    print ('regularization strength = %f, score = %f') % (reg, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальное качество логистической регрессии над всеми признаками получилось 65%, это на 4% меньше, чем показатель градиентного бустинга. Скорость работы логистической регрессии в разы быстрее, чем у градиентного бустинга.\n",
    "\n",
    "Объяснить разницу\n",
    "\n",
    "#### Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = features\n",
    "del X[u'lobby_type'],X[u'r1_hero'],X[u'r2_hero'],X[u'r3_hero'],X[u'r4_hero'],X[u'r5_hero']\n",
    "del X[u'd1_hero'],X[u'd2_hero'],X[u'd3_hero'],X[u'd4_hero'],X[u'd5_hero']\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:16.874939\n",
      "regularization strength = 0.010000, score = 0.653935\n",
      "Time elapsed: 0:00:18.756939\n",
      "regularization strength = 0.110000, score = 0.654194\n",
      "Time elapsed: 0:00:19.481813\n",
      "regularization strength = 0.210000, score = 0.654246\n",
      "Time elapsed: 0:00:15.631732\n",
      "regularization strength = 0.310000, score = 0.654247\n",
      "Time elapsed: 0:00:24.950345\n",
      "regularization strength = 0.410000, score = 0.654247\n",
      "Time elapsed: 0:00:15.203889\n",
      "regularization strength = 0.510000, score = 0.654257\n",
      "Time elapsed: 0:00:16.006301\n",
      "regularization strength = 0.610000, score = 0.654257\n",
      "Time elapsed: 0:00:15.067789\n",
      "regularization strength = 0.710000, score = 0.654247\n",
      "Time elapsed: 0:00:15.760332\n",
      "regularization strength = 0.810000, score = 0.654247\n",
      "Time elapsed: 0:00:17.206616\n",
      "regularization strength = 0.910000, score = 0.654247\n"
     ]
    }
   ],
   "source": [
    "for reg in np.arange(0.01,1.0,0.1):#0.31-1.0 best score = 0.654247\n",
    "    LR = LogisticRegression(penalty = 'l2', C = reg)\n",
    "    start_time = datetime.datetime.now()\n",
    "    predict = cross_val.cross_val_predict(LR, X, target, cv = cv)\n",
    "    score = roc_auc_score(target,predict)\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "    print ('regularization strength = %f, score = %f') % (reg, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество предсказаний не улучшилось. Значит для логистической регрессии эти признаки в числовом виде незначимые.\n",
    "#### 3 . Сколько различных идентификаторов героев существует в данной игре?\n",
    "Посчитаем количество уникальных идентификаторов героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 112\n"
     ]
    }
   ],
   "source": [
    "id_num = features.r1_hero.unique().max()\n",
    "#Проверим выбрав уникальные идентификаторы по всем столбцам с героями\n",
    "h = np.concatenate([features.r1_hero.unique(),features.r2_hero.unique(),features.r3_hero.unique(),\n",
    "                    features.r4_hero.unique(),features.r5_hero.unique(),features.d1_hero.unique(),\n",
    "                    features.d2_hero.unique(),features.d3_hero.unique(),features.d4_hero.unique(),\n",
    "                    features.d5_hero.unique()])\n",
    "print id_num, np.max(np.unique(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В игре 108 идентификаторов героев.\n",
    "#### Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?\n",
    "Закодируем информацию о героях с помощью мешка слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pick = np.zeros((features.shape[0], id_num))\n",
    "\n",
    "for i, match_id in enumerate(features.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, features.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, features.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "#Добавим столбцы к признакам\n",
    "for i in xrange(id_num):\n",
    "    features['hero_%d' % i] = X_pick[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:21.485700\n",
      "regularization strength = 0.001000, score = 0.682015\n",
      "Time elapsed: 0:00:29.415787\n",
      "regularization strength = 0.053579, score = 0.682058\n",
      "Time elapsed: 0:00:32.174494\n",
      "regularization strength = 0.106158, score = 0.682018\n",
      "Time elapsed: 0:00:28.528078\n",
      "regularization strength = 0.158737, score = 0.682027\n",
      "Time elapsed: 0:00:29.536610\n",
      "regularization strength = 0.211316, score = 0.682038\n",
      "Time elapsed: 0:00:31.432241\n",
      "regularization strength = 0.263895, score = 0.682049\n",
      "Time elapsed: 0:00:31.598233\n",
      "regularization strength = 0.316474, score = 0.682050\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X = StandardScaler().fit_transform(features)\n",
    "cv = cross_val.KFold(len(features),n_folds=5, shuffle=True)\n",
    "\n",
    "for reg in np.linspace(0.001, 1.0, num=20):#np.arange(0.005,0.01,0.001):\n",
    "    LR = LogisticRegression(penalty = 'l2', C = reg)\n",
    "    start_time = datetime.datetime.now()\n",
    "    predict = cross_val.cross_val_predict(LR, X, target, cv = cv)\n",
    "    score = roc_auc_score(target,predict)\n",
    "    print 'Time elapsed:', datetime.datetime.now() - start_time\n",
    "    print ('regularization strength = %f, score = %f') % (reg, score) #0.6819 1.8\n",
    "    print predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.001     ,  0.05357895,  0.10615789,  0.15873684,  0.21131579,\n",
       "        0.26389474,  0.31647368,  0.36905263,  0.42163158,  0.47421053,\n",
       "        0.52678947,  0.57936842,  0.63194737,  0.68452632,  0.73710526,\n",
       "        0.78968421,  0.84226316,  0.89484211,  0.94742105,  1.        ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.001, 1.0, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
